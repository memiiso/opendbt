{
  "metadata": {
    "dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json",
    "dbt_version": "1.9.4",
    "generated_at": "2025-05-15T18:01:15.425030Z",
    "invocation_id": "4a81f777-5b15-45b3-8c88-b08d0f7bb9ea",
    "env": {}
  },
  "results": [
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.370700Z",
          "completed_at": "2025-05-15T18:01:15.374387Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.374594Z",
          "completed_at": "2025-05-15T18:01:15.374600Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.004414081573486328,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_core_table1",
      "compiled": true,
      "compiled_code": "with source_data as (\n    select 1 as id, 'row1' as row_data\n    union all\n    select 2 as id, 'row1' as row_data\n)\n\nSELECT *\nFROM source_data",
      "relation_name": "\"dev\".\"core\".\"my_core_table1\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.375609Z",
          "completed_at": "2025-05-15T18:01:15.378100Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.378308Z",
          "completed_at": "2025-05-15T18:01:15.378311Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0031371116638183594,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_executedlt_model",
      "compiled": true,
      "compiled_code": "import dlt\nfrom dlt.pipeline import TPipeline\n\n\n@dlt.resource(\n    columns={\"event_tstamp\": {\"data_type\": \"timestamp\", \"precision\": 3}},\n    primary_key=\"event_id\",\n)\ndef events():\n    yield [{\"event_id\": 1, \"event_tstamp\": \"2024-07-30T10:00:00.123\"},\n           {\"event_id\": 2, \"event_tstamp\": \"2025-02-30T10:00:00.321\"}]\n\n\ndef model(dbt, pipeline: TPipeline):\n    \"\"\"\n\n    :param dbt:\n    :param pipeline: Pre-configured dlt pipeline. dlt target connection and dataset is pre-set using the model config!\n    :return:\n    \"\"\"\n    dbt.config(materialized=\"executedlt\")\n    print(\"========================================================\")\n    print(f\"INFO: DLT Pipeline pipeline_name:{pipeline.pipeline_name}\")\n    print(f\"INFO: DLT Pipeline dataset_name:{pipeline.dataset_name}\")\n    print(f\"INFO: DLT Pipeline dataset_name:{pipeline}\")\n    print(f\"INFO: DLT Pipeline staging:{pipeline.staging}\")\n    print(f\"INFO: DLT Pipeline destination:{pipeline.destination}\")\n    print(f\"INFO: DLT Pipeline _pipeline_storage:{pipeline._pipeline_storage}\")\n    print(f\"INFO: DLT Pipeline _schema_storage:{pipeline._schema_storage}\")\n    print(f\"INFO: DLT Pipeline state:{pipeline.state}\")\n    print(f\"INFO: DBT this:{dbt.this}\")\n    print(\"========================================================\")\n    load_info = pipeline.run(events(), table_name=str(str(dbt.this).split('.')[-1]).strip('\"'))\n    print(load_info)\n    row_counts = pipeline.last_trace.last_normalize_info\n    print(row_counts)\n    print(\"========================================================\")\n    return None\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"dev\"\n    schema = \"core\"\n    identifier = \"my_executedlt_model\"\n    \n    def __repr__(self):\n        return '\"dev\".\"core\".\"my_executedlt_model\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n",
      "relation_name": "\"dev\".\"core\".\"my_executedlt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.379280Z",
          "completed_at": "2025-05-15T18:01:15.382080Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.382289Z",
          "completed_at": "2025-05-15T18:01:15.382292Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0034627914428710938,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_executepython_dlt_model",
      "compiled": true,
      "compiled_code": "import dlt\n\n\n@dlt.resource(\n    columns={\"event_tstamp\": {\"data_type\": \"timestamp\", \"precision\": 3}},\n    primary_key=\"event_id\",\n)\ndef events():\n    yield [{\"event_id\": 1, \"event_tstamp\": \"2024-07-30T10:00:00.123\"},\n           {\"event_id\": 2, \"event_tstamp\": \"2025-02-30T10:00:00.321\"}]\n\n\ndef model(dbt, session):\n    dbt.config(materialized=\"executepython\")\n    print(\"========================================================\")\n    print(f\"INFO: DLT Version:{dlt.version.__version__}\")\n    print(f\"INFO: DBT Duckdb Session:{type(session)}\")\n    print(f\"INFO: DBT Duckdb Connection:{type(session._env.conn)}\")\n    print(\"========================================================\")\n    p = dlt.pipeline(\n        pipeline_name=\"dbt_dlt\",\n        destination=dlt.destinations.duckdb(session._env.conn),\n        dataset_name=dbt.this.schema,\n        dev_mode=False,\n    )\n    load_info = p.run(events())\n    print(load_info)\n    row_counts = p.last_trace.last_normalize_info\n    print(row_counts)\n    print(\"========================================================\")\n    return None\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"dev\"\n    schema = \"core\"\n    identifier = \"my_executepython_dlt_model\"\n    \n    def __repr__(self):\n        return '\"dev\".\"core\".\"my_executepython_dlt_model\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n",
      "relation_name": "\"dev\".\"core\".\"my_executepython_dlt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.383207Z",
          "completed_at": "2025-05-15T18:01:15.385343Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.385543Z",
          "completed_at": "2025-05-15T18:01:15.385546Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.002765655517578125,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_executepython_model",
      "compiled": true,
      "compiled_code": "import os\nimport platform\n\nfrom dbt import version\n\n\ndef print_info():\n    _str = f\"name:{os.name}, system:{platform.system()} release:{platform.release()}\"\n    _str += f\"\\npython version:{platform.python_version()}, dbt:{version.__version__}\"\n    print(_str)\n\n\ndef model(dbt, session):\n    dbt.config(materialized=\"executepython\")\n    print(\"==================================================\")\n    print(\"========IM LOCALLY EXECUTED PYTHON MODEL==========\")\n    print(\"==================================================\")\n    print_info()\n    print(\"==================================================\")\n    print(\"===============MAKE DBT GREAT AGAIN===============\")\n    print(\"==================================================\")\n    return None\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"dev\"\n    schema = \"core\"\n    identifier = \"my_executepython_model\"\n    \n    def __repr__(self):\n        return '\"dev\".\"core\".\"my_executepython_model\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n",
      "relation_name": "\"dev\".\"core\".\"my_executepython_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.386444Z",
          "completed_at": "2025-05-15T18:01:15.388683Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.388882Z",
          "completed_at": "2025-05-15T18:01:15.388885Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.002866983413696289,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_executesql_dbt_model",
      "compiled": true,
      "compiled_code": "\n\n\ncreate or replace table my_execute_dbt_model\nas\n\nselect 123 as column1",
      "relation_name": "\"dev\".\"core\".\"my_executesql_dbt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.389806Z",
          "completed_at": "2025-05-15T18:01:15.392211Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.392403Z",
          "completed_at": "2025-05-15T18:01:15.392406Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0030357837677001953,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_first_dbt_model",
      "compiled": true,
      "compiled_code": "\n\nwith source_data as (\n    select 1 as id, 'test-value' as data_value, 'test-value' as column_3\n    union all\n    select 1 as id, 'test-value' as data_value, 'test-value' as column_3\n    union all\n    select 2 as id, 'test-value' as data_value, 'test-value' as column_3\n    union all\n    select null as id, 'test-value' as data_value, 'test-value' as column_3\n)\nSELECT *\nFROM source_data\n-- where id is not null",
      "relation_name": "\"dev\".\"core\".\"my_first_dbt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.393375Z",
          "completed_at": "2025-05-15T18:01:15.397001Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.397198Z",
          "completed_at": "2025-05-15T18:01:15.397201Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.004261970520019531,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtfinance.my_cross_project_ref_model",
      "compiled": true,
      "compiled_code": "select\n id,\n row_data,\n count(*) as num_rows\nfrom \"dev\".\"core\".\"my_core_table1\"\n-- fake second dependency  \"dev\".\"core\".\"my_executepython_model\"\ngroup by 1,2",
      "relation_name": "\"dev\".\"finance\".\"my_cross_project_ref_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.398112Z",
          "completed_at": "2025-05-15T18:01:15.400272Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.400463Z",
          "completed_at": "2025-05-15T18:01:15.400466Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0027790069580078125,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_failing_dbt_model",
      "compiled": true,
      "compiled_code": "select non_exists_column as my_failing_column\nfrom \"dev\".\"core\".\"my_first_dbt_model\"\nwhere id = 1",
      "relation_name": "\"dev\".\"core\".\"my_failing_dbt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.401387Z",
          "completed_at": "2025-05-15T18:01:15.403803Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.404000Z",
          "completed_at": "2025-05-15T18:01:15.404003Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0030541419982910156,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "model.dbtcore.my_second_dbt_model",
      "compiled": true,
      "compiled_code": "SELECT\n    t1.id AS pk_id,\n    t1.data_value AS data_value1,\n    CONCAT(t1.column_3, '-concat-1', t1.data_value, t2.row_data) AS data_value2,\n    t3.event_tstamp AS event_tstamp\nFROM \"dev\".\"core\".\"my_first_dbt_model\" AS t1\nLEFT JOIN \"dev\".\"core\".\"my_core_table1\" AS t2 ON t1.id = t2.id\nLEFT JOIN \"dev\".\"core\".\"my_executedlt_model\" AS t3 ON t1.id = t3.event_id\nWHERE t1.id IN (1, 2)",
      "relation_name": "\"dev\".\"core\".\"my_second_dbt_model\"",
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.404991Z",
          "completed_at": "2025-05-15T18:01:15.408939Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.409137Z",
          "completed_at": "2025-05-15T18:01:15.409140Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.004628896713256836,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "test.dbtcore.not_null_my_first_dbt_model_id.5fb22c2710",
      "compiled": true,
      "compiled_code": "\n    \n    \n\n\n\nselect id\nfrom \"dev\".\"core\".\"my_first_dbt_model\"\nwhere id is null\n\n\n",
      "relation_name": null,
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.410051Z",
          "completed_at": "2025-05-15T18:01:15.413241Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.413441Z",
          "completed_at": "2025-05-15T18:01:15.413444Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0038330554962158203,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "test.dbtcore.unique_my_first_dbt_model_id.16e066b321",
      "compiled": true,
      "compiled_code": "\n    \n    \n\nselect\n    id as unique_field,\n    count(*) as n_records\n\nfrom \"dev\".\"core\".\"my_first_dbt_model\"\nwhere id is not null\ngroup by id\nhaving count(*) > 1\n\n\n",
      "relation_name": null,
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.414359Z",
          "completed_at": "2025-05-15T18:01:15.419818Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.420020Z",
          "completed_at": "2025-05-15T18:01:15.420024Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0061070919036865234,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "test.dbtcore.not_null_my_second_dbt_model_pk_id.b08c51696a",
      "compiled": true,
      "compiled_code": "\n    \n    \n\n\n\nselect pk_id\nfrom \"dev\".\"core\".\"my_second_dbt_model\"\nwhere pk_id is null\n\n\n",
      "relation_name": null,
      "batch_results": null
    },
    {
      "status": "success",
      "timing": [
        {
          "name": "compile",
          "started_at": "2025-05-15T18:01:15.420923Z",
          "completed_at": "2025-05-15T18:01:15.423545Z"
        },
        {
          "name": "execute",
          "started_at": "2025-05-15T18:01:15.423757Z",
          "completed_at": "2025-05-15T18:01:15.423760Z"
        }
      ],
      "thread_id": "Thread-10",
      "execution_time": 0.0032682418823242188,
      "adapter_response": {},
      "message": null,
      "failures": null,
      "unique_id": "test.dbtcore.unique_my_second_dbt_model_pk_id.b8b65b2a4f",
      "compiled": true,
      "compiled_code": "\n    \n    \n\nselect\n    pk_id as unique_field,\n    count(*) as n_records\n\nfrom \"dev\".\"core\".\"my_second_dbt_model\"\nwhere pk_id is not null\ngroup by pk_id\nhaving count(*) > 1\n\n\n",
      "relation_name": null,
      "batch_results": null
    }
  ],
  "elapsed_time": 0.09994196891784668,
  "args": {
    "empty_catalog": false,
    "compile": true,
    "warn_error_options": {
      "include": [],
      "exclude": []
    },
    "which": "generate",
    "state_modified_compare_vars": false,
    "use_colors": true,
    "version_check": true,
    "log_format_file": "debug",
    "require_explicit_package_overrides_for_builtin_materializations": true,
    "log_level": "info",
    "source_freshness_run_project_hooks": false,
    "static": false,
    "populate_cache": true,
    "defer": false,
    "select": [],
    "require_batched_execution_for_custom_microbatch_strategy": false,
    "print": true,
    "state_modified_compare_more_unrendered_values": false,
    "strict_mode": false,
    "require_yaml_configuration_for_mf_time_spines": false,
    "send_anonymous_usage_stats": true,
    "log_file_max_bytes": 10485760,
    "exclude": [],
    "log_format": "default",
    "partial_parse_file_diff": true,
    "write_json": true,
    "invocation_command": "dbt test_dbt_docs.py::TestDbtDocs::test_run_docs_generate",
    "quiet": false,
    "target": "dev",
    "vars": {},
    "favor_state": false,
    "log_path": "/Users/simseki/IdeaProjects/opendbt/tests/resources/dbtfinance/logs",
    "macro_debugging": false,
    "require_nested_cumulative_type_params": false,
    "require_resource_names_without_spaces": false,
    "static_parser": true,
    "show_resource_report": false,
    "printer_width": 80,
    "introspect": true,
    "cache_selected_only": false,
    "log_level_file": "debug",
    "skip_nodes_if_on_run_start_fails": false,
    "profiles_dir": "/Users/simseki/IdeaProjects/opendbt/tests/resources/dbtfinance",
    "project_dir": "/Users/simseki/IdeaProjects/opendbt/tests/resources/dbtfinance",
    "use_colors_file": true,
    "partial_parse": true,
    "indirect_selection": "eager"
  }
}